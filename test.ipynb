{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT LIBRARIES & CREATE CONNECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as sa\n",
    "import mysql.connector\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "\n",
    "ENGLISH_WORDS = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = 'localhost'\n",
    "USER = 'root'\n",
    "DATABASE = 'goodreads'\n",
    "PASSWORD = getpass.getpass(f'Enter password for {USER}: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time:  2023-05-29 16:53:57\n"
     ]
    }
   ],
   "source": [
    "def getconn():\n",
    "    conn = mysql.connector.connect(\n",
    "        host=HOST,\n",
    "        user=USER,\n",
    "        password=PASSWORD,\n",
    "        database=DATABASE\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "pool = sa.create_engine(\n",
    "    \"mysql+mysqlconnector://\",\n",
    "    creator=getconn,\n",
    ")\n",
    "\n",
    "with pool.connect() as db_conn:\n",
    "    results = db_conn.execute(sa.text(\"SELECT NOW()\")).fetchone()\n",
    "    print(\"Current time: \", results[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goodreads_book_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  goodreads_book_id\n",
       "0           2767052\n",
       "1                 3\n",
       "2             41865\n",
       "3              2657\n",
       "4              4671"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_id_query = sa.text(\n",
    "    \"SELECT goodreads_book_id FROM books;\"\n",
    ")\n",
    "book_id = pd.read_sql_query(book_id_query, con=pool.connect())\n",
    "book_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = book_id.goodreads_book_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id\n",
       "0       1\n",
       "1      10\n",
       "2     100\n",
       "3    1000\n",
       "4   10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_query = sa.text(\n",
    "    \"SELECT DISTINCT(user_id) FROM new_ratings_;\"\n",
    ")\n",
    "user_id = pd.read_sql_query(user_id_query, con=pool.connect())\n",
    "user_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '10', '100', '1000', '10000']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_list = user_id.user_id.tolist()\n",
    "user_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_ratings(user_id):\n",
    "#     query = sa.text(\n",
    "#         f\"SELECT goodreads_book_id as book_id, rating FROM new_ratings_ WHERE user_id = {user_id};\"\n",
    "#     )\n",
    "#     result = pd.read_sql_query(query, con=pool.connect())\n",
    "#     books_list = result.book_id.tolist()\n",
    "#     ratings_list = result.rating.apply(lambda x: round(x*0.2,4)).tolist()\n",
    "#     return books_list, ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_ratings_df = pd.DataFrame(columns=list(['user_id']+id_list))\n",
    "# for user in user_list[:5]:\n",
    "#     user_books, user_ratings = get_ratings(user)\n",
    "#     user_profile = pd.DataFrame({'user_id': [user]}, columns=user_ratings_df.columns)\n",
    "#     user_profile.loc[0,user_books] = user_ratings\n",
    "#     user_profile.fillna(0, inplace=True)\n",
    "#     user_ratings_df = pd.concat([user_ratings_df, user_profile], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>processed_descr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767052</td>\n",
       "      <td>could survive wild every one make sure live se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>harry potter idea famous raised miserable aunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41865</td>\n",
       "      <td>three absolutely part know dominant part might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2657</td>\n",
       "      <td>unforgettable novel childhood sleepy southern ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4671</td>\n",
       "      <td>alternate cover edition great third book supre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   goodreads_book_id                                    processed_descr\n",
       "0            2767052  could survive wild every one make sure live se...\n",
       "1                  3  harry potter idea famous raised miserable aunt...\n",
       "2              41865  three absolutely part know dominant part might...\n",
       "3               2657  unforgettable novel childhood sleepy southern ...\n",
       "4               4671  alternate cover edition great third book supre..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query =  sa.text(\n",
    "    \"SELECT * FROM processed_description;\"\n",
    ")\n",
    "\n",
    "df = pd.read_sql_query(query, con=pool.connect())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(docs):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens_list = []\n",
    "    for doc in docs:\n",
    "        tokens = nltk.word_tokenize(doc)\n",
    "        tokens = [token.lower() for token in tokens if token.lower() not in stop_words and token.isalpha() and token.lower() in ENGLISH_WORDS]        \n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        tokens_list.append(tokens)\n",
    "    return tokens_list\n",
    "    \n",
    "def get_recommendations( id, num_recommends=5):\n",
    "    idx = indices[id]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:num_recommends]\n",
    "    item_indices = [i[0] for i in sim_scores]\n",
    "    return data[id].iloc[item_indices]\n",
    "\n",
    "docs_data = df['processed_descr']\n",
    "tokens_list = [[' '.join(doc)][0] for doc in preprocess_text(docs_data)]\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(tokens_list)  \n",
    "cosine_sim = cosine_similarity(tfidf_matrix)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'could survive wild every one make sure live see morning place known north nation shining surrounded twelve outlying harsh cruel line forcing send one boy one girl twelve eighteen participate annual hunger fight death live alone mother younger sister death sentence forward take sister place close dead survival second nature without really meaning becomes contender win start making weight survival humanity life love'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf_score(doc, corpus):\n",
    "  \"\"\"\n",
    "  Calculates the TF-IDF score of a document.\n",
    "\n",
    "  Args:\n",
    "    doc: The document to calculate the TF-IDF score for.\n",
    "    corpus: The corpus of documents.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary mapping each word in the document to its TF-IDF score.\n",
    "  \"\"\"\n",
    "\n",
    "  # Calculate the term frequency of each word in the document.\n",
    "  term_frequencies = {}\n",
    "  for word in doc:\n",
    "    if word not in term_frequencies:\n",
    "      term_frequencies[word] = 0\n",
    "    term_frequencies[word] += 1\n",
    "\n",
    "  # Calculate the inverse document frequency of each word in the corpus.\n",
    "  inverse_document_frequencies = {}\n",
    "  for word in corpus:\n",
    "    if word not in inverse_document_frequencies:\n",
    "      inverse_document_frequencies[word] = 0\n",
    "    inverse_document_frequencies[word] += 1\n",
    "\n",
    "  # Calculate the TF-IDF score of each word in the document.\n",
    "  tf_idf_scores = {}\n",
    "  for word in term_frequencies:\n",
    "    tf_idf_scores[word] = term_frequencies[word] * math.log(len(corpus) / inverse_document_frequencies[word])\n",
    "\n",
    "  return tf_idf_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tfidf_matrix.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'could': 9.884814287270506,\n",
       " 'survive': 9.884814287270506,\n",
       " 'wild': 9.884814287270506,\n",
       " 'every': 9.884814287270506,\n",
       " 'one': 29.654442861811518,\n",
       " 'make': 9.884814287270506,\n",
       " 'sure': 9.884814287270506,\n",
       " 'live': 19.769628574541013,\n",
       " 'see': 9.884814287270506,\n",
       " 'morning': 9.884814287270506,\n",
       " 'place': 19.769628574541013,\n",
       " 'known': 9.884814287270506,\n",
       " 'north': 9.884814287270506,\n",
       " 'nation': 9.884814287270506,\n",
       " 'shining': 9.884814287270506,\n",
       " 'surrounded': 9.884814287270506,\n",
       " 'twelve': 19.769628574541013,\n",
       " 'outlying': 9.884814287270506,\n",
       " 'harsh': 9.884814287270506,\n",
       " 'cruel': 9.884814287270506,\n",
       " 'line': 9.884814287270506,\n",
       " 'forcing': 9.884814287270506,\n",
       " 'send': 9.884814287270506,\n",
       " 'boy': 9.884814287270506,\n",
       " 'girl': 9.884814287270506,\n",
       " 'eighteen': 9.884814287270506,\n",
       " 'participate': 9.884814287270506,\n",
       " 'annual': 9.884814287270506,\n",
       " 'hunger': 9.884814287270506,\n",
       " 'fight': 9.884814287270506,\n",
       " 'death': 19.769628574541013,\n",
       " 'alone': 9.884814287270506,\n",
       " 'mother': 9.884814287270506,\n",
       " 'younger': 9.884814287270506,\n",
       " 'sister': 19.769628574541013,\n",
       " 'sentence': 9.884814287270506,\n",
       " 'forward': 9.884814287270506,\n",
       " 'take': 9.884814287270506,\n",
       " 'close': 9.884814287270506,\n",
       " 'dead': 9.884814287270506,\n",
       " 'survival': 19.769628574541013,\n",
       " 'second': 9.884814287270506,\n",
       " 'nature': 9.884814287270506,\n",
       " 'without': 9.884814287270506,\n",
       " 'really': 9.884814287270506,\n",
       " 'meaning': 9.884814287270506,\n",
       " 'becomes': 9.884814287270506,\n",
       " 'contender': 9.884814287270506,\n",
       " 'win': 9.884814287270506,\n",
       " 'start': 9.884814287270506,\n",
       " 'making': 9.884814287270506,\n",
       " 'weight': 9.884814287270506,\n",
       " 'humanity': 9.884814287270506,\n",
       " 'life': 9.884814287270506,\n",
       " 'love': 9.884814287270506}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = tfidf.get_feature_names_out()\n",
    "get_tf_idf_score(nltk.word_tokenize(sample), corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
